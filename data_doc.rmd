---
title: "Capital_Idea"
author: "Ethan Tenison"
date: "6/7/2020"
output: html_document
---

```{r libraries, message=FALSE}
#load libraries
library(haven)
library(dplyr)
library(janitor)
library(stringr)
library(readr)
library(ggplot2)
library(tidyr)
library(readxl)
library(anytime)
library(lubridate)
library(stringr)
library(broom)
library(janitor)


```




```{r read}

surveys_casenotes <- read_excel("data/Semester Surveys with Case Notes.xlsx")
surveys_casenotes$`Case_Notes.Record ID` <- as.numeric(surveys_casenotes$`Case_Notes.Record ID`)

meetinglength <- surveys_casenotes$`Session Minutes`

#Adding demogrpahic information
demographics <- read_excel("data/demographics.xlsx", 
    col_types = c("numeric", "skip", "numeric", 
        "text", "text", "text", "text", "text", 
        "text", "text", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "text", "text", "text", 
        "skip", "skip", "skip", "text", "numeric", 
        "skip", "text", "numeric", "numeric", 
        "text", "text", "text"))




```

## Data Cleaning 

The data set contains tons of duplicated information. Most students complete the information survey once a semester, although that is not always the case. However, each time a navigator interacts with the student, they input the survey information in again. 
```{r clean}


#Data cleaning demographic data
demographics$Race[is.na(demographics$Race)] <- "Other"

for (i in 1:length(demographics$Race)){
                if(demographics$Race[i] == "Black or African American AND White" |
                   demographics$Race[i] == "American Indian or Alaska Native, Black or African American" |
                   demographics$Race[i] == "White, Other" | 
                   demographics$Race[i] == "White|Biracial" |
                   demographics$Race[i] == "White|N/A" |
                   demographics$Race[i] == "Other|hispanic" |
                   demographics$Race[i] == "Black or African American, Other" |
                   demographics$Race[i] == "White|Latino" |
                   demographics$Race[i] == "American Indian or Alaska Native, White" |
                   demographics$Race[i] == "American Indian or Alaska Native|Asian|Native Hawaiian or Pacific Islander|White" |
                   demographics$Race[i] == "American Indian or Alaska Native|White|pakistani" |
                   demographics$Race[i] == "American Indian or Alaska Native|White" |
                   demographics$Race[i] == "Black or African American|White" |
                   demographics$Race[i] == "American Indian or Alaska Native|Asian|Black or African American" |
                   demographics$Race[i] == "White|Afghan" |
                   demographics$Race[i] == "Asian|White" |
                   demographics$Race[i] == "honduran" |
                   demographics$Race[i] == "White|Adopted" |
                   demographics$Race[i] == "Black or African American|White|Mexican" |
                   demographics$Race[i] == "American Indian or Alaska Native|Black or African American")        {
                  demographics$Race[i] <- "Multiracial"
                }
                else if(demographics$Race[i] == "Somali" |
                        demographics$Race[i] == "Ethiopian"){ 
                  
                        demographics$Race[i] <- "Black or African American"
                }
                else if(demographics$Race[i] == "Other|unknown" |
                        demographics$Race[i] == "Doesnâ€™t matter."){        
                        demographics$Race[i] <- "Other"
                }
                else if(demographics$Race[i] == "hispanic" |
                        demographics$Race[i] == "Mexican" |
                        demographics$Race[i] == "Hispanic" |
                        demographics$Race[i] == "Mexican American" |
                        demographics$Race[i] == "White|Hispanic" | 
                         demographics$Race[i] == "Hispanic/Latino" ){        
                        demographics$Race[i] <- "White"
                }
}

demographics$`Living Arrangement`[is.na(demographics$`Living Arrangement`)] <- "Other"

for (i in 1:length(demographics$`Living Arrangement`)){
                  if(demographics$`Living Arrangement`[i] == "Living with parents" | 
                     demographics$`Living Arrangement`[i] == "Currently staying with son and at home" |
                     demographics$`Living Arrangement`[i] == "Living with my parents" |
                     demographics$`Living Arrangement`[i] == "Lives with parent" |
                     demographics$`Living Arrangement`[i] == "parents house hold"){        
                    demographics$`Living Arrangement`[i] <- "Lives with Family"
                  }
                 else if(demographics$`Living Arrangement`[i] == "Renting in a family house" |
                         demographics$`Living Arrangement`[i] == "One Family"){        
                    demographics$`Living Arrangement`[i] <- "One family household"
                 }
                 else if(demographics$`Living Arrangement`[i] == "Has one roommate" |
                         demographics$`Living Arrangement`[i] == "no place of my own. Living with a friend" |
                         demographics$`Living Arrangement`[i] == "Live with my sister and roomates"){        
                    demographics$`Living Arrangement`[i] <- "Other Arrangement"
                 }
}

#Joining casenotes and demographic data
surveys_casenotes <- left_join(surveys_casenotes, demographics, by = c("Case_Notes.Record ID" = "Record ID"))
surveys_casenotes$Race[is.na(surveys_casenotes$Race)] <- "Other"
surveys_casenotes$`Living Arrangement`[is.na(surveys_casenotes$`Living Arrangement`)] <- "Other Arrangement"

#Converting dates to date formate
surveys_casenotes$`Survey Date` <- anytime::anydate(surveys_casenotes$`Survey Date`)

#Creating a variable for semester
surveys_casenotes$semester <- ""

for (i in 1:length(surveys_casenotes$`Survey Date`)){
  
  if(surveys_casenotes$`Survey Date`[i] < as.Date("2020-01-01")){        
                    surveys_casenotes$semester[i] <- "Fall 2019"
  }
  else if(surveys_casenotes$`Survey Date`[i] >= as.Date("2020-01-01") & surveys_casenotes$`Survey Date`[i] <= as.Date("2020-06-01") ){
                    surveys_casenotes$semester[i] <- "Spring 2020"
  }
  
}


#Add up total minutes for each student each semester 
surveys_casenotes$`Session Minutes` <- str_replace_all(surveys_casenotes$`Session Minutes`, " Minutes", "")
surveys_casenotes$`Session Minutes` <- as.numeric(surveys_casenotes$`Session Minutes`)

#Changing names to all upper 
surveys_casenotes$First <- toupper(surveys_casenotes$First)
surveys_casenotes$Last <- toupper(surveys_casenotes$Last)


#Getting rid of duplicate rows and sum all the minutes a navigator spent interacting with student per semester
survey <- surveys_casenotes %>% group_by_at(setdiff(names(surveys_casenotes), c("Session Minutes","Case Note", "Note Code", "Note Date Entered","Type of Contact","Note Importance","Note Meeting Date","Semester_Survey.Record ID", "Case_Notes.Record ID"))) %>% summarize(total_session_minutes = sum(`Session Minutes`))

#Removing entries were students took the entire survey multiple times per semester
surveyfall <- filter(survey, semester == "Fall 2019")
surveyfall <- surveyfall[(!duplicated(surveyfall$First) & !duplicated(surveyfall$Last) ), ]

surveyspring <- filter(survey, semester == "Spring 2020")
surveyspring <- surveyspring[(!duplicated(surveyspring$First) & !duplicated(surveyspring$Last) ), ]

surveys_casenotes <- bind_rows(surveyfall, surveyspring)

surveys_casenotes$`Household Languages`[is.na(surveys_casenotes$`Household Languages`)] <- "Unknown"

#Creating a list of bilingual students 
bilingual_and_English <- unique(surveys_casenotes$`Household Languages`[grep("English", surveys_casenotes$`Household Languages`)])
bilingual_and_English <- bilingual_and_English[-1]
 
#putting variable for home language 
for (i in 1:length(surveys_casenotes$`Household Languages`)){
    for (j in 1:length(bilingual_and_English)){
  
      if(surveys_casenotes$`Household Languages`[i] == bilingual_and_English[j]){        
                        surveys_casenotes$`Household Languages`[i] <- "Bilingual"
      }
      
    }
}

for (i in 1:length(surveys_casenotes$`Household Languages`)){
  if(surveys_casenotes$`Household Languages`[i] != "English" & surveys_casenotes$`Household Languages`[i] != "Bilingual" &
     surveys_casenotes$`Household Languages`[i] != "Spanish" & surveys_casenotes$`Household Languages`[i] != "Unknown"){        
                        surveys_casenotes$`Household Languages`[i] <- "non_english_spanish"
      }
  
}


```



```{r plots}

#GGPLOTS

for(i in 1:ncol(surveys_casenotes)){
  

print(
  ggplot(surveys_casenotes, aes(x=surveys_casenotes[[i]])) +
  geom_histogram(stat = "count", fill = "lightblue") +
  xlab(colnames(surveys_casenotes)[i])
  )
  
  
}

```

# Demographic data

```{r demographics}

library(readxl)
demographics <- read_excel("data/demographics.xlsx")



```

# Assumptions of a logistic regression model 

* The outcome is a binary or dichotomous variable like yes vs no, positive vs negative, 1 vs 0.

* There is a linear relationship between the logit of the outcome and each predictor variables. Recall that the logit function is logit(p) = log(p/(1-p)), where p is the probabilities of the outcome (see Chapter @ref(logistic-regression)).

* There is no influential values (extreme values or outliers) in the continuous predictors

* There is no high intercorrelations (i.e. multicollinearity) among the predictors.

# creating binary variable 
```{r binary}
#turn off scientific notation
options(scipen=999)

#Creating a binary variable for whether a student is in good standing or not. 
for (i in 1:length(surveys_casenotes$`7 What is your current academic standing at ACC?`)) {
    if (surveys_casenotes$`7 What is your current academic standing at ACC?`[i] == "Good standing -") {
        surveys_casenotes$good_standing[i] <- 1
    }
    else {
      surveys_casenotes$good_standing[i] <- 0
    }
}

```

#Removing undesireable columns
```{r}
#removing nas from selected columns
mult_reg <- surveys_casenotes %>% ungroup() %>% dplyr::select(-c(`6a Are you enrolled in College Prep?`,`6b Are you awaiting acceptance into a`,
                                                                 `11d Please specify your OTHER financial`,`23a If yes, please explain`,
                                                                 `Is this an Intake Applicant or a current`, `Survey Date`, `First`,
                                                                 `Last`,`semester`, `26 What are your top two academic goals`,
                                                                 `27 What are your top two personal goals`,
                                                                 `28 What are your top two motivators for`,
                                                                 `29 How can your Career Navigator better`,
                                                                 `Estimated Graduation Date`,
                                                                 `1c Who is your assigned Career Navigator?`,
                                                                 "Academic Priority Level", "Financial Priority Level",
                                                                 "Situational Priority Level", "7 What is your current academic standing at ACC?",
                                                                 `16 Which best describes your current living situation?`,
                                                                 `Career Goal`, "Component", City ,"Do you have children?",
                                                                 "If no diploma or GED obtained, Highest...","SAGE was taken in:",                                                                                        "SAGE Reasoning", "SAGE Interest", "Educational Status", "Race",
                                                                 "12 Over the past 3 months, have you had legal issues related to child support?",    
                                                                 "12a Over the past 3 months, have you had legal issues related to housing eviction?",   
                                                                 "12b Over the past 3 months, have you had legal issues related to bankrupcy?",          
                                                                 "12c Over the past 3 months, have you had legal issues related to criminal offenses (not including traffic violations)?",
                                                                 "12d Over the past 3 months, have you had legal issues related to tickets or traffic violations?"
                                                                 ))



```



```{r full_model}
#Running the model

mult_reg <- clean_names(mult_reg)
mult_reg <- mult_reg %>% drop_na(total_session_minutes) %>% select(-c(x15_what_best_describes_your_current_childcare_arrangements,
                                                                      x4_last_semester_how_many_credit_hours_registered,
                                                                      x5_last_semester_how_many_credit_hours_completed))  

#removing row 237 because it had high leverage 
mult_reg <- mult_reg[-c(237), ]

model <- glm(good_standing ~ ., family=binomial(link='logit'),data=mult_reg,  maxit = 100)

summary(model)
df <- as.data.frame(tidy(model))
#Race didnt' seem to be important factor in whether a student was in good academic statnding, but being hispanic was

```


```{r parsimonious_model}

x4model2 <- dplyr::select(mult_reg,good_standing ,academic_total_score ,financial_burden_total_score , situational_total_score , total_session_minutes , are_you_of_hispanic_or_latino_origin , 	tabe_mathematics , x6_how_many_credit_hours_currently_registered_this_semester , gender , status , 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc)

#Removing 521 because it is highly influential
x4model2 <- x4model2[-c(521), ]

x4model2 <- na.omit(x4model2)

model2 <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc ,family=binomial(link='logit'),data=x4model2)

summary(model2)
df2 <- as.data.frame(tidy(model2))

#Converting log odds to probability 
source("https://sebastiansauer.github.io/Rcode/logit2prob.R")
logit2prob(coef(model2))


# Predict the probability (p) of diabete positivity
probabilities <- predict(model2, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)

# good_standing_mex <-factor(hispanics$good_standing,c(0,1),labels=c('No','Yes'))
# SurT_mex<-table(good_standing_mex)addmargins(SurT_mex)
# prop.table(SurT_mex)
```


```{r test_logistic}

#################################Linearly assumption 
# Select only numeric predictors
mydata <- x4model2 %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

#create scatter plots 
ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

################################Influential Values
plot(model2, which = 4, id.n = 3)

# Extract model results
model.data <- augment(model2) %>% 
  mutate(index = 1:n()) 


model.data %>% top_n(3, .cooksd)

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = factor(good_standing)), alpha = .5) +
  theme_bw()

test_influential <- model.data %>% filter(abs(.std.resid) > 3)

################################Multicollinearity 
library(car)

car::vif(model2)
```


```{r log_prediction}
library(caTools)

x4model3 <- x4model2

#Splitting the data into test and train 
set.seed(27)
split = sample.split(x4model3$good_standing, SplitRatio = 0.70)
train = subset(x4model3, split == TRUE)
test = subset(x4model3, split == FALSE)


#Running model on the train set
model3 <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc ,family=binomial(link='logit'),data=train)

summary(model3)
df3 <- as.data.frame(tidy(model3))



#Compute confusion matrix 
library(caret)
p <- predict(model3, test, type = "response")
print(summary(p))


p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, test[["good_standing"]]))



#COmputing the accuracy 
#For test set
print("Test set")
t <- table(p_class, test[["good_standing"]]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))


```

# Cross Validation for the logistic regression model 
Based on the results, it's clear that the model is better at predicting than being completely random. I think it's difficult to assess with CV because the samples are too small for logistic regression. 

```{r log_kfoldcv}
set.seed(27)
rand <- sample(nrow(x4model3))

k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
k4row <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]

k1fold <- x4model3[k1row,]
k2fold <- x4model3[k2row,]
k3fold <- x4model3[k3row,]
k4fold <- x4model3[k4row,]
k5fold <- x4model3[k5row,]

print("Summary Statistics for 5 folds")
summary(k1fold$good_standing)
summary(k2fold$good_standing)
summary(k3fold$good_standing)
summary(k4fold$good_standing)
summary(k5fold$good_standing)


#model with k1fold as test 
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k3fold,k4fold,k5fold))
p <- predict(model, k1fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k1fold[["good_standing"]]))
t <- table(p_class, k1fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#model with k2fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k1fold, k3fold,k4fold,k5fold))
p <- predict(model, k2fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k2fold[["good_standing"]]))
t <- table(p_class, k2fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#Model with k3fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k4fold,k5fold))
p <- predict(model, k3fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k3fold[["good_standing"]]))
t <- table(p_class, k3fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#Model with k4fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k3fold,k5fold))
p <- predict(model, k4fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k4fold[["good_standing"]]))
t <- table(p_class, k4fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#Model with k5fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k3fold,k4fold))
p <- predict(model, k5fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k5fold[["good_standing"]]))
t <- table(p_class, k5fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))




```


```{r knn}
library(class)
library(gmodels)
library(caret)

#KNN has higher total accuracy rate, but
dfknn <- x4model2
  
set.seed(27)
dmy <- dummyVars(" ~ .", data = dfknn)
dfknn <- data.frame(predict(dmy, newdata = dfknn))
split = sample.split(dfknn$good_standing, SplitRatio = 0.7)
train_knn = subset(dfknn, split == TRUE)
train_labels = train_knn[["good_standing"]]
train_knn[is.na(train_knn)] <- 0

test_knn = subset(dfknn, split == FALSE)
test_labels = test_knn[["good_standing"]]
test_knn[is.na(test_knn)] <- 0


dfknn_prediction = class::knn(train= train_knn, test = test_knn, cl= train_labels, k = 5)
CrossTable(x= test_labels, y= dfknn_prediction, chisq = FALSE)



```

```{r tree_full}


tree <- dfknn




### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(good_standing ~ ., data = df_train, mindev = 0.001, minsize = 5)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)

```

```{r tree_prune}
### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 3 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 3)

summary(mod.tree.prune)

par(xpd = TRUE)
plot(mod.tree.prune)
title(main= "Good Standing")
text(mod.tree.prune, pretty = 1,  splits = TRUE, cex=.8)


# There is not enough variation. Based on the 50% threshold I was using all the leads would convert. 


```

# The logistic regression actually did a better job at predicting those that were going to be in bad standing 
```{r tree_predict}
### Predict Conversion, using the pruned tree ###
tree$good_standing.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$good_standing.Pred.Class <- ifelse(tree$good_standing.Pred > 0.6, "1", "0")
table(tree$good_standing.Pred.Class)

tree$good_standing <- as.character(tree$good_standing)

#For training set
print("Train set")
t <-table(Truegood_standing = tree$good_standing[train], Predgood_standing = tree$good_standing.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


#For test set
print("Test set")
t <-table(Truegood_standing = tree$good_standing[test], Predgood_standing = tree$good_standing.Pred.Class[test]) #How many instances were misclassified? Error
t 
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))





```