---
title: "Capital_Idea"
author: "Ethan Tenison"
date: "6/7/2020"
output: html_document
---

```{r libraries, message=FALSE}
#load libraries
library(haven)
library(dplyr)
library(janitor)
library(stringr)
library(readr)
library(ggplot2)
library(tidyr)
library(readxl)
library(anytime)
library(lubridate)
library(stringr)
library(broom)
library(janitor)


```




```{r read}

surveys_casenotes <- read_excel("data/Semester Surveys with Case Notes.xlsx")
surveys_casenotes$`Case_Notes.Record ID` <- as.numeric(surveys_casenotes$`Case_Notes.Record ID`)

meetinglength <- surveys_casenotes$`Session Minutes`

#Adding demogrpahic information
demographics <- read_excel("data/demographics.xlsx", 
    col_types = c("numeric", "skip", "numeric", 
        "text", "text", "text", "text", "text", 
        "text", "text", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "text", "text", "text", 
        "skip", "skip", "skip", "text", "numeric", 
        "skip", "text", "numeric", "numeric", 
        "text", "text", "text"))




```

## Data Cleaning 

The data set contains tons of duplicated information. Most students complete the information survey once a semester, although that is not always the case. However, each time a navigator interacts with the student, they input the survey information in again. 
```{r clean}


#Data cleaning demographic data
demographics$Race[is.na(demographics$Race)] <- "Other"

for (i in 1:length(demographics$Race)){
                if(demographics$Race[i] == "Black or African American AND White" |
                   demographics$Race[i] == "American Indian or Alaska Native, Black or African American" |
                   demographics$Race[i] == "White, Other" | 
                   demographics$Race[i] == "White|Biracial" |
                   demographics$Race[i] == "White|N/A" |
                   demographics$Race[i] == "Other|hispanic" |
                   demographics$Race[i] == "Black or African American, Other" |
                   demographics$Race[i] == "White|Latino" |
                   demographics$Race[i] == "American Indian or Alaska Native, White" |
                   demographics$Race[i] == "American Indian or Alaska Native|Asian|Native Hawaiian or Pacific Islander|White" |
                   demographics$Race[i] == "American Indian or Alaska Native|White|pakistani" |
                   demographics$Race[i] == "American Indian or Alaska Native|White" |
                   demographics$Race[i] == "Black or African American|White" |
                   demographics$Race[i] == "American Indian or Alaska Native|Asian|Black or African American" |
                   demographics$Race[i] == "White|Afghan" |
                   demographics$Race[i] == "Asian|White" |
                   demographics$Race[i] == "honduran" |
                   demographics$Race[i] == "White|Adopted" |
                   demographics$Race[i] == "Black or African American|White|Mexican" |
                   demographics$Race[i] == "American Indian or Alaska Native|Black or African American")        {
                  demographics$Race[i] <- "Multiracial"
                }
                else if(demographics$Race[i] == "Somali" |
                        demographics$Race[i] == "Ethiopian"){ 
                  
                        demographics$Race[i] <- "Black or African American"
                }
                else if(demographics$Race[i] == "Other|unknown" |
                        demographics$Race[i] == "Doesnâ€™t matter."){        
                        demographics$Race[i] <- "Other"
                }
                else if(demographics$Race[i] == "hispanic" |
                        demographics$Race[i] == "Mexican" |
                        demographics$Race[i] == "Hispanic" |
                        demographics$Race[i] == "Mexican American" |
                        demographics$Race[i] == "White|Hispanic" | 
                         demographics$Race[i] == "Hispanic/Latino" ){        
                        demographics$Race[i] <- "White"
                }
}

demographics$`Living Arrangement`[is.na(demographics$`Living Arrangement`)] <- "Other"

for (i in 1:length(demographics$`Living Arrangement`)){
                  if(demographics$`Living Arrangement`[i] == "Living with parents" | 
                     demographics$`Living Arrangement`[i] == "Currently staying with son and at home" |
                     demographics$`Living Arrangement`[i] == "Living with my parents" |
                     demographics$`Living Arrangement`[i] == "Lives with parent" |
                     demographics$`Living Arrangement`[i] == "parents house hold"){        
                    demographics$`Living Arrangement`[i] <- "Lives with Family"
                  }
                 else if(demographics$`Living Arrangement`[i] == "Renting in a family house" |
                         demographics$`Living Arrangement`[i] == "One Family"){        
                    demographics$`Living Arrangement`[i] <- "One family household"
                 }
                 else if(demographics$`Living Arrangement`[i] == "Has one roommate" |
                         demographics$`Living Arrangement`[i] == "no place of my own. Living with a friend" |
                         demographics$`Living Arrangement`[i] == "Live with my sister and roomates"){        
                    demographics$`Living Arrangement`[i] <- "Other Arrangement"
                 }
}

#Joining casenotes and demographic data
surveys_casenotes <- left_join(surveys_casenotes, demographics, by = c("Case_Notes.Record ID" = "Record ID"))
surveys_casenotes$Race[is.na(surveys_casenotes$Race)] <- "Other"
surveys_casenotes$`Living Arrangement`[is.na(surveys_casenotes$`Living Arrangement`)] <- "Other Arrangement"

#Converting dates to date formate
surveys_casenotes$`Survey Date` <- anytime::anydate(surveys_casenotes$`Survey Date`)

#Creating a variable for semester
surveys_casenotes$semester <- ""

for (i in 1:length(surveys_casenotes$`Survey Date`)){
  
  if(surveys_casenotes$`Survey Date`[i] < as.Date("2020-01-01")){        
                    surveys_casenotes$semester[i] <- "Fall 2019"
  }
  else if(surveys_casenotes$`Survey Date`[i] >= as.Date("2020-01-01") & surveys_casenotes$`Survey Date`[i] <= as.Date("2020-06-01") ){
                    surveys_casenotes$semester[i] <- "Spring 2020"
  }
  
}


#Add up total minutes for each student each semester 
surveys_casenotes$`Session Minutes` <- str_replace_all(surveys_casenotes$`Session Minutes`, " Minutes", "")
surveys_casenotes$`Session Minutes` <- as.numeric(surveys_casenotes$`Session Minutes`)

#Changing names to all upper 
surveys_casenotes$First <- toupper(surveys_casenotes$First)
surveys_casenotes$Last <- toupper(surveys_casenotes$Last)


#Getting rid of duplicate rows and sum all the minutes a navigator spent interacting with student per semester
survey <- surveys_casenotes %>% group_by_at(setdiff(names(surveys_casenotes), c("Session Minutes","Case Note", "Note Code", "Note Date Entered","Type of Contact","Note Importance","Note Meeting Date","Semester_Survey.Record ID", "Case_Notes.Record ID"))) %>% summarize(total_session_minutes = sum(`Session Minutes`))

#Removing entries were students took the entire survey multiple times per semester
surveyfall <- filter(survey, semester == "Fall 2019")
surveyfall <- surveyfall[(!duplicated(surveyfall$First) & !duplicated(surveyfall$Last) ), ]

surveyspring <- filter(survey, semester == "Spring 2020")
surveyspring <- surveyspring[(!duplicated(surveyspring$First) & !duplicated(surveyspring$Last) ), ]

surveys_casenotes <- bind_rows(surveyfall, surveyspring)

surveys_casenotes$`Household Languages`[is.na(surveys_casenotes$`Household Languages`)] <- "Unknown"

#Creating a list of bilingual students 
bilingual_and_English <- unique(surveys_casenotes$`Household Languages`[grep("English", surveys_casenotes$`Household Languages`)])
bilingual_and_English <- bilingual_and_English[-1]
 
#putting variable for home language 
for (i in 1:length(surveys_casenotes$`Household Languages`)){
    for (j in 1:length(bilingual_and_English)){
  
      if(surveys_casenotes$`Household Languages`[i] == bilingual_and_English[j]){        
                        surveys_casenotes$`Household Languages`[i] <- "Bilingual"
      }
      
    }
}

for (i in 1:length(surveys_casenotes$`Household Languages`)){
  if(surveys_casenotes$`Household Languages`[i] != "English" & surveys_casenotes$`Household Languages`[i] != "Bilingual" &
     surveys_casenotes$`Household Languages`[i] != "Spanish" & surveys_casenotes$`Household Languages`[i] != "Unknown"){        
                        surveys_casenotes$`Household Languages`[i] <- "non_english_spanish"
      }
  
}


```



```{r plots}

#GGPLOTS

for(i in 1:ncol(surveys_casenotes)){
  

print(
  ggplot(surveys_casenotes, aes(x=surveys_casenotes[[i]])) +
  geom_histogram(stat = "count", fill = "lightblue") +
  xlab(colnames(surveys_casenotes)[i])
  )
  
  
}

```

```{r session_minutes}
library(extrafont)
library(readxl)
windowsFonts(Times=windowsFont("Times"))


theme_set(theme_bw())

g <- ggplot(surveys_casenotes, aes(x=total_session_minutes)) +
  theme(legend.background = element_rect(fill = "transparent"), 
         legend.key = element_rect(fill = "transparent"), 
         legend.spacing = unit(-1, "lines"),
         panel.background = element_blank(), axis.line = element_line(colour = "black"),
         text=element_text(family="Times", face = "bold", size=16), 
         axis.text.x = element_text(vjust = 1, hjust = 1),
         axis.title.y.right = element_text( vjust = 2.5),
         axis.title.x = element_text(vjust = -0.5),
         plot.title = element_text(hjust = 0.5),
         legend.position = "bottom")+
  geom_histogram(stat = "count", fill = "blue") +
  xlab("Total Session Minutes") +
  ylab("Count") +
  ggtitle("Histogram of Navigator Session Minutes \n (Fall and Spring Semester)")
  
  
ggsave("images/session_minutes.png", width = 10, height = 7, dpi = 500)


```

```{r age}

library(extrafont)
library(readxl)
windowsFonts(Times=windowsFont("Times"))


theme_set(theme_bw())

g <- ggplot(surveys_casenotes, aes(x=`Age at intake`)) +
  theme(legend.background = element_rect(fill = "transparent"), 
         legend.key = element_rect(fill = "transparent"), 
         legend.spacing = unit(-1, "lines"),
         panel.background = element_blank(), axis.line = element_line(colour = "black"),
         text=element_text(family="Times", face = "bold", size=16), 
         axis.text.x = element_text(vjust = 1, hjust = 1),
         axis.title.y.right = element_text( vjust = 2.5),
         axis.title.x = element_text(vjust = -0.5),
         plot.title = element_text(hjust = 0.5),
         legend.position = "bottom")+
  geom_histogram(stat = "count", fill = "darkgreen") +
  xlab("Age at Intake") +
  ylab("Count") +
  ggtitle("Histogram of Age \n (Fall and Spring Semester)")
  
  
ggsave("images/age.png", width = 10, height = 7, dpi = 500)

```

# creating binary variable 
```{r binary}
#turn off scientific notation
options(scipen=999)

#Creating a binary variable for whether a student is in good standing or not. 
for (i in 1:length(surveys_casenotes$`7 What is your current academic standing at ACC?`)) {
    if (surveys_casenotes$`7 What is your current academic standing at ACC?`[i] == "Good standing -") {
        surveys_casenotes$good_standing[i] <- 1
    }
    else {
      surveys_casenotes$good_standing[i] <- 0
    }
}

```


```{r, full_model, message=FALSE, warning=FALSE}

mult_reg = surveys_casenotes %>%
          ungroup() %>%
          dplyr::select(-c(`6a Are you enrolled in College Prep?`,
                           `6b Are you awaiting acceptance into a`,
                           `11d Please specify your OTHER financial`,`23a If yes, please explain`,
                           `Is this an Intake Applicant or a current`, `Survey Date`, `First`,
                           `Last`,`semester`, `26 What are your top two academic goals`,
                           `27 What are your top two personal goals`,
                           `28 What are your top two motivators for`,
                           `29 How can your Career Navigator better`,
                           `Estimated Graduation Date`,Status,
                           `1c Who is your assigned Career Navigator?`,
                           "Academic Priority Level", "Financial Priority Level",
                           "Situational Priority Level", "7 What is your current academic standing at ACC?",
                           `Career Goal`, "Component", City ,
                           "If no diploma or GED obtained, Highest...","SAGE was taken in:","SAGE Interest",
                           "Educational Status")) 
            


#Running the model
library(MASS)
mult_reg <- clean_names(mult_reg)
mult_reg <- mult_reg %>% drop_na(total_session_minutes) %>% dplyr::select(-c(
                                                                      x4_last_semester_how_many_credit_hours_registered,
                                                                      x5_last_semester_how_many_credit_hours_completed,
                                                                      academic_total_score,
                                                                      financial_burden_total_score,
                                                                      situational_total_score
                                                                      ))  

#Setting the NA values to Unknown
mult_reg$x24_what_form_of_transportation_do_you_most_commonly_use[is.na(mult_reg$x24_what_form_of_transportation_do_you_most_commonly_use)] <- "Unknown"
mult_reg$x12a_over_the_past_3_months_have_you_had_legal_issues_related_to_housing_eviction[is.na(mult_reg$x12a_over_the_past_3_months_have_you_had_legal_issues_related_to_housing_eviction)] <- "Unknown"
mult_reg$x12b_over_the_past_3_months_have_you_had_legal_issues_related_to_bankrupcy[is.na(mult_reg$x12b_over_the_past_3_months_have_you_had_legal_issues_related_to_bankrupcy)] <- "Unknown"
mult_reg$x12c_over_the_past_3_months_have_you_had_legal_issues_related_to_criminal_offenses_not_including_traffic_violations[is.na(mult_reg$x12c_over_the_past_3_months_have_you_had_legal_issues_related_to_criminal_offenses_not_including_traffic_violations)] <- "Unknown"
mult_reg$x12d_over_the_past_3_months_have_you_had_legal_issues_related_to_tickets_or_traffic_violations[is.na(mult_reg$x12d_over_the_past_3_months_have_you_had_legal_issues_related_to_tickets_or_traffic_violations)] <- "Unknown"
mult_reg$do_you_have_children[is.na(mult_reg$do_you_have_children)] <- "Unknown"

#removing row 237 because it had high leverage 
mult_reg <- mult_reg[-c(237), ]

#Remove NAs for it to work 
mult_reg = na.omit(mult_reg)
model <- glm(good_standing ~ ., family=binomial(link='logit'),data=mult_reg) %>%  stepAIC(trace = FALSE) #added backward stepwise selection

# summary(model) the tidy model works better 
df <- as.data.frame(tidy(model))
#Race didnt' seem to be important factor in whether a student was in good academic statnding, but being hispanic was


#Computing the odds
logit2odds <- function(logit){
    odds <- exp(logit)
    return(odds)
}

odds <- data.frame(as.list(logit2odds(coef(model))))
odds['forwide'] = 'Yes'
library(tidyr)
odds_long <- gather(odds, term, odds, X.Intercept.:total_session_minutes, factor_key=TRUE)
odds_long = odds_long[,-1]
odds_long$term = as.character(odds_long$term)

#Subsetting significant variables
df_significant <- dplyr::filter(df, p.value < .1)
df_significant <- left_join(df_significant, odds_long, by = "term")

#putting in the values for variables that could not be joined
df_significant$odds[df_significant$term == "x6_how_many_credit_hours_currently_registered_this_semester10 - 12 credit hours (usually four classes) -"] = 4.9840301
df_significant$odds[df_significant$term == "x6_how_many_credit_hours_currently_registered_this_semester4 - 6 credit hours (usually two classes) -"] = 	2.2273206
df_significant$odds[df_significant$term == "x9_over_the_past_6_months_were_you_able_to_pay_your_rent_mortgage_or_housing_expense_on_time_and_in_full_every_monthNot applicable (select this if you are homeless, currently living with a friend or family without rent, or don't have housing expenses at this time)"] = 	0.2936733
df_significant$odds[df_significant$term == "x17_how_would_you_consider_your_present_living_arrangementPermanent (I'll be here more than 6 months)"] = 2.4921778
df_significant$odds[df_significant$term == "x16_which_best_describes_your_current_living_situationOwn a home (paying mortgage)"] = 29.2040600
df_significant$odds[df_significant$term == "x12a_over_the_past_3_months_have_you_had_legal_issues_related_to_housing_evictionYes - Housing Eviction legal issues"] = 0.1066242



#Calculating probability 
source("https://sebastiansauer.github.io/Rcode/logit2prob.R")
probs <- data.frame(as.list(logit2prob(coef(model))))


write.csv(df_significant, "data/significant_variables.csv")

```



#Test the full model


```{r full_model_predictions}

library(caTools)

mult_reg2 <- mult_reg

#Splitting the data into test and train 
set.seed(27)
split = sample.split(mult_reg2$good_standing, SplitRatio = 0.70)
train = subset(mult_reg2, split == TRUE)
test = subset(mult_reg2, split == FALSE)



#Running model on the train set

model2 <- glm(good_standing ~ ., family=binomial(link='logit'),data=train) %>%  stepAIC(trace = FALSE) #added backward stepwise selection

# summary(model) the tidy model works better 
df <- as.data.frame(tidy(model2))


#Compute confusion matrix 
library(caret)
p <- predict(model2, test, type = "response")
print(summary(p))


p_class <- ifelse(p > 0.95, "Predict 1", "Predict 0")
print(table(p_class, test[["good_standing"]]))



#COmputing the accuracy 
#For test set
print("Test set")
t <- table(p_class, test[["good_standing"]]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate
print("Accuracy Rate")
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print("True Negative")
print((t[1,1])/ (t[2,1] +t[1,1]))
print("True Positive")
print((t[2,2])/ (t[2,2] +t[1,2]))


#Using a high threshold 
```

# We need to get to the bottom of the fact that Hispanics had a higher likelihood of being in bad standing with the university 

```{r full_model_hispanic_only, warning = FALSE, message= FALSE}


mult_reg = surveys_casenotes %>%
          ungroup() %>%
          dplyr::select(-c(`6a Are you enrolled in College Prep?`,
                           `6b Are you awaiting acceptance into a`,
                           `11d Please specify your OTHER financial`,`23a If yes, please explain`,
                           `Is this an Intake Applicant or a current`, `Survey Date`, `First`,
                           `Last`,`semester`, `26 What are your top two academic goals`,
                           `27 What are your top two personal goals`,
                           `28 What are your top two motivators for`,
                           `29 How can your Career Navigator better`,
                           `Estimated Graduation Date`,Status,
                           `1c Who is your assigned Career Navigator?`,
                           "Academic Priority Level", "Financial Priority Level",
                           "Situational Priority Level", "7 What is your current academic standing at ACC?",
                           `Career Goal`, "Component", City ,
                           "If no diploma or GED obtained, Highest...","SAGE was taken in:","SAGE Interest",
                           "Educational Status")) 
            


#Running the model
library(MASS)
mult_reg <- clean_names(mult_reg)
mult_reg <- mult_reg %>% drop_na(total_session_minutes) %>% dplyr::select(-c(
                                                                      x4_last_semester_how_many_credit_hours_registered,
                                                                      x5_last_semester_how_many_credit_hours_completed,
                                                                      academic_total_score,
                                                                      financial_burden_total_score,
                                                                      situational_total_score
                                                                      ))  

#Setting the NA values to Unknown
mult_reg$x24_what_form_of_transportation_do_you_most_commonly_use[is.na(mult_reg$x24_what_form_of_transportation_do_you_most_commonly_use)] <- "Unknown"
mult_reg$x12a_over_the_past_3_months_have_you_had_legal_issues_related_to_housing_eviction[is.na(mult_reg$x12a_over_the_past_3_months_have_you_had_legal_issues_related_to_housing_eviction)] <- "Unknown"
mult_reg$x12b_over_the_past_3_months_have_you_had_legal_issues_related_to_bankrupcy[is.na(mult_reg$x12b_over_the_past_3_months_have_you_had_legal_issues_related_to_bankrupcy)] <- "Unknown"
mult_reg$x12c_over_the_past_3_months_have_you_had_legal_issues_related_to_criminal_offenses_not_including_traffic_violations[is.na(mult_reg$x12c_over_the_past_3_months_have_you_had_legal_issues_related_to_criminal_offenses_not_including_traffic_violations)] <- "Unknown"
mult_reg$x12d_over_the_past_3_months_have_you_had_legal_issues_related_to_tickets_or_traffic_violations[is.na(mult_reg$x12d_over_the_past_3_months_have_you_had_legal_issues_related_to_tickets_or_traffic_violations)] <- "Unknown"
mult_reg$do_you_have_children[is.na(mult_reg$do_you_have_children)] <- "Unknown"

#removing row 237 because it had high leverage 
mult_reg <- mult_reg[-c(237), ]

#Remove NAs for it to work 
mult_reg = na.omit(mult_reg)
hispanics = mult_reg %>% 
                    dplyr::filter(are_you_of_hispanic_or_latino_origin == "Yes") %>%
                    dplyr::select(-c(are_you_of_hispanic_or_latino_origin))

model_hispanic <- glm(good_standing ~ ., family=binomial(link='logit'),data=hispanics) %>% stepAIC(trace = FALSE)
df_hispanic <- as.data.frame(tidy(model_hispanic))

#Computing the odds
logit2odds <- function(logit){
    odds <- exp(logit)
    return(odds)
}

odds <- data.frame(as.list(logit2odds(coef(model_hispanic))))
odds['forwide'] = 'Yes'
library(tidyr)
odds_long <- gather(odds, term, odds, X.Intercept.:sage_reasoningReasoning..6...Approximate.grade.level.College.3..Years, factor_key=TRUE)
odds_long = odds_long[,-1]
odds_long$term = as.character(odds_long$term)

#Subsetting significant variables
df_significant_hispanic <- dplyr::filter(df_hispanic, p.value < .1)
df_significant_hispanic <- left_join(df_significant_hispanic, odds_long, by = "term")
df_significant_hispanic$odds[df_significant_hispanic$term == "x17_how_would_you_consider_your_present_living_arrangementPermanent (I'll be here more than 6 months)"] = 	2.967836136501983
df_significant_hispanic$odds[df_significant_hispanic$term == "x11a_over_the_past_3_months_has_medical_debt_been_a_cause_of_financial_stress_or_hardship_for_youYes - Medical Debt"] = 5.043680790936799

write.csv(df_significant_hispanic, "data/significant_hispanic_variables.csv")


```


# Diagnostic Tests for Logistic Regresssion 
-The tests below can be used to improve the logistic regression model. Ultimately they were not used for the final model, but they may be of interest for future iterations of this project. 


### Assumptions of a logistic regression model 

* The outcome is a binary or dichotomous variable like yes vs no, positive vs negative, 1 vs 0.

* There is a linear relationship between the logit of the outcome and each predictor variables. Recall that the logit function is logit(p) = log(p/(1-p)), where p is the probabilities of the outcome (see Chapter @ref(logistic-regression)).

* There is no influential values (extreme values or outliers) in the continuous predictors

* There is no high intercorrelations (i.e. multicollinearity) among the predictors.
```{r test_logistic, eval=FALSE, include=FALSE}


#################################Linearly assumption 
# Select only numeric predictors
mydata <- x4model2 %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

#create scatter plots 
ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

################################Influential Values
plot(model2, which = 4, id.n = 3)

# Extract model results
model.data <- augment(model2) %>% 
  mutate(index = 1:n()) 


model.data %>% top_n(3, .cooksd)

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = factor(good_standing)), alpha = .5) +
  theme_bw()

test_influential <- model.data %>% filter(abs(.std.resid) > 3)

################################Multicollinearity 
library(car)

car::vif(model2)
```
The odds of being in good standing with the university are 70% lower for hispanics than non hispanics. The probability of being in good standing is approx. 77% compared to approx 89% of the rest. 


# Cross Validation for the logistic regression model 
Based on the results, it's clear that the model is better at predicting than being completely random. I think it's difficult to assess with CV because the samples are too small for logistic regression. 

* Cross validations shows a weaker accuracy score but this might be because there are not enough samples. 

```{r log_kfoldcv}
set.seed(27)
rand <- sample(nrow(x4model3))

k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
k4row <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]

k1fold <- x4model3[k1row,]
k2fold <- x4model3[k2row,]
k3fold <- x4model3[k3row,]
k4fold <- x4model3[k4row,]
k5fold <- x4model3[k5row,]

print("Summary Statistics for 5 folds")
summary(k1fold$good_standing)
summary(k2fold$good_standing)
summary(k3fold$good_standing)
summary(k4fold$good_standing)
summary(k5fold$good_standing)


#model with k1fold as test 
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k3fold,k4fold,k5fold))
p <- predict(model, k1fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k1fold[["good_standing"]]))
t <- table(p_class, k1fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#model with k2fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k1fold, k3fold,k4fold,k5fold))
p <- predict(model, k2fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k2fold[["good_standing"]]))
t <- table(p_class, k2fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#Model with k3fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k4fold,k5fold))
p <- predict(model, k3fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k3fold[["good_standing"]]))
t <- table(p_class, k3fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#Model with k4fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k3fold,k5fold))
p <- predict(model, k4fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k4fold[["good_standing"]]))
t <- table(p_class, k4fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

#Model with k5fold as test
model <- glm(good_standing ~ poly(academic_total_score, 2) + situational_total_score + poly(total_session_minutes, 3) + are_you_of_hispanic_or_latino_origin + 	poly(tabe_mathematics, 2) + x6_how_many_credit_hours_currently_registered_this_semester + gender + status + 	x8_do_you_think_there_are_any_issues_that_might_keep_you_from_maintaining_good_standing_with_acc  ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k3fold,k4fold))
p <- predict(model, k5fold, type = "response")
p_class <- ifelse(p > 0.9, "Predict 1", "Predict 0")
print(table(p_class, k5fold[["good_standing"]]))
t <- table(p_class, k5fold[["good_standing"]])
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))




```



```{r tree_full}


tree <- mult_reg




### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(good_standing ~ ., data = df_train, mindev = 0.001, minsize = 5)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)

```

```{r tree_prune}
### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 3 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 3)

summary(mod.tree.prune)

par(xpd = TRUE)
plot(mod.tree.prune)
title(main= "Good Standing")
text(mod.tree.prune, pretty = 1,  splits = TRUE, cex=.8)


# There is not enough variation. Based on the 50% threshold I was using all the leads would convert. 


```

# The logistic regression actually did a better job at predicting those that were going to be in bad standing 

* True negative is very low 
```{r tree_predict}
### Predict Conversion, using the pruned tree ###
tree$good_standing.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$good_standing.Pred.Class <- ifelse(tree$good_standing.Pred > 0.80, "1", "0")
table(tree$good_standing.Pred.Class)

tree$good_standing <- as.character(tree$good_standing)

#For training set
print("Train set")
t <-table(Truegood_standing = tree$good_standing[train], Predgood_standing = tree$good_standing.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


#For test set
print("Test set")
t <-table(Truegood_standing = tree$good_standing[test], Predgood_standing = tree$good_standing.Pred.Class[test]) #How many instances were misclassified? Error
t 
#Accuracy Rate 
#Accuracy Rate
print("Accuracy Rate")
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print("True Negative")
print((t[1,1])/ (t[2,1] +t[1,1]))
print("True Positive")
print((t[2,2])/ (t[2,2] +t[1,2]))





```